## 第二节

随机变量（Random Variables）是研究不确定性现象的基本工具，是从样本空间映射到实数轴的函数$X:\Omega \rightarrow \mathbb{R}$，样本空间的每一个点都会在实数轴有一个数对应，随机变量的作用是把样本空间给量化，样本空间的点是随机试验的结果，随机变量使得能用数学工具去研究随机试验，随机变量自身没有不确定性，它是确定性的函数。根据样本空间是否可数分成两类：

* Discrete 分布律$P(X=x_k)=P_k$
* Continuous 概率密度$f_X(x)$

随机过程就是一大堆或一组的随机变量。其角标未必表达是时间，只是对若干随机变量的标记。如果表达是时间，随机过程看作是过程，时间意味着在考察某种发展（evolution）随时间变化的规律。其角标还未必是一维的，还有可能是二维的$X_{ij}$，称为随机场（Random Field）。

* $X_1,X_2,...,X_n$，这样标定称为离散指标（Discrete Index）；

* $X(t)$，这样标定称为连续指标（Continuous Index）；一方面是时间的函数，另一方面具有随机性，严格意义上是一个二元函数$X(w,t)$，时间参数$t$提供其“过程”属性，样本空间的样本点（样本参数）$\omega$提供其“随机”属性，谓之“随机过程”。

随机过程关心的是随机过程在不同时刻取值的随机变量之间的相互关联（交互）（Relation（Interaction））。

联合分布(Joint Distribution) $f_{X_1,X_2}(x_1,x_2)$:

* $f_{X_1,X_2}(x_1,x_2)\geq 0$
* $\int_{-\infty}^{\infty} f_{X_1,X_2}(x_1,x_2)\, dx_1dx_2=1$
* Boundary Distribution $f_{X_1}(x_1)=\int_{-\infty}^{\infty}f_{X_1,X_2}(x_1,x_2)\, dx_2$

联合分布是两个随机变量联合起来的分布行为：

$P(x_1 < X_1\leq x_1+\Delta x_1, x_2 < X_2\leq x_2+\Delta x_2)\approx f_{X_1,X_2}(x_1,x_2)\Delta x_1 \Delta x_2$

一个二元函数复杂度很高，研究随机变量之间的关联，联合分布虽然包含的信息很丰富、描述问题很透彻，但是很复杂，希望引入新的工具。

![image-20220410102605112](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/987b8743d4a53682dffc56d07f7f42dd-image-20220410102605112-cf7fff.png)

两者之间不存在关联，$X_2$的分布没有随着$X_1$​的分布发生变化。

独立，两者的联合分布可以写成边缘分布的乘积：

$f_{X_1,X_2}(x_1,x_2)=f_{X_1}(x_1)f_{X_2}(x_2)$

![image-20220410102657030](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/bd2e222a4c0e2c283d6f6c7b7237b1a7-image-20220410102657030-67109c.png)

两者之间存在相互关联（Interaction），$X_2$的分布随着$X_1$的分布发生变化。

![image-20220410102949782](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/c2f58b8450973caa5565b525efbcebf7-image-20220410102949782-5d0884.png)

两者之间存在线性关联（Correlation，linear），即相关性，$X_2$随着$X_1$增大而变大。

n个随机变量的联合分布，用条件手段来简化，控制一部分随机变量的随机性，随机性暂时看作是确定的，研究少量随机变量的随机性，复杂度得到下降。n个随机变量的联合分布分解成n个一元函数的乘积。但是条件是很复杂的，带来了约束（Constraint），把困难从目标转移到约束，并没有解决问题。恒同变换并没有简化问题，化简不等于简化，化简是把问题化为原有形式，简化要引入假设（Assumption），假设并不是退缩。假设的三个特点：

* Simple Description，陈述非常简单；
* Really Effective，确实有效；
* Widely Applicable，假设应用特别广泛，在现实中广泛成立。

> 约束本身是难度的一部分：两点之间直线最短；如果在球面上，北京纽约、北京夏威夷距离差不多，在球面上问题变得复杂；椭球上，用椭圆积分解决问题；任意曲面，怎么走最短，是测地线问题（Geodesic）。

$$
\begin{align}
P(X_1,X_2,...,X_n) & = P(X_n|X_{n-1},...,X_1)P(X_{n-1},...,X_1)\\
 & = P(X_n|X_{n-1},...,X_1)P(X_{n-1}|X_{n-2},...,X_1)...P(X_2|X_1)P(X_1)
\end{align}
$$

条件太复杂使得矛盾转移，并没有解决矛盾，条件住很多时刻，可以只保留离目标时刻的一个最近时刻，称为马尔科夫性。这种假设是马尔可夫假设。

> 不马尔可夫的都是逆天的，马尔可夫的东西才是会存活下来的 。——真人语录

随机过程就学习两种关联：相关性、马尔科夫性。
$$
\begin{align}
P(X_1,X_2,...,X_n) & = P(X_n|X_{n-1},...,X_1)P(X_{n-1},...,X_1)\\
 & = P(X_n|X_{n-1})P(X_{n-1}|X_{n-2})...P(X_2|X_1)P(X_1)
\end{align}
$$
研究$X_1,X_2$的关联，首先需要有一个度量（距离）Metric(Distance) ，均方度量$d(X_1,X_2)=(E|X_1-x_2|^2)^{1/2}$，开方是为了确保是距离，距离要满足三角不等式。距离大关联大，距离小关联小
$$
E|X_1-x_2|^2=E|X_1|^2+E|X_2|^2-2E|X_1X_2|^2
$$
$\Longrightarrow$ 更关心交叉项$E(X_1X_2)$，这个计算叫做相关。两个随机变量相关可以写成下式。
$$
E(X_1X_2)=E(X_1)E(X_2)
$$
满足上式，称为是不相关的（Uncorrelated）。即做中心化$E(X_1-EX_1)(X_2-EX_2)=E(X_1X_2)-E(X_1)E(X_2)$，此时为0。

**独立（Independence）一定不相关，不相关不一定独立。**独立时，联合分布可以写成边缘分布的乘积，推导出相关，见下式：
$$
\begin{align}
E(X_1X_2)&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x_1x_2f_{X_1,X_2}(x_1,x_2)\,dx_1dx_2\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x_1x_2f_{X_1}(x_1)f_{X_2}(x_2)\,dx_1dx_2\\
&=\int_{-\infty}^{\infty}x_1f_{X_1}(x_1)\,dx_1\int_{-\infty}^{\infty}x_2f_{X_2}(x_2)\,dx_2=E(X_1)E(X_2)
\end{align}
$$

不相关、不独立的例子：
$$
\Theta\sim U(0,2\pi)\quad X_1=\cos (\theta),X_2=\sin(\theta),X_1^2+X_2^2=1\\
E(X_1)=\int_{-\infty}^\infty x_1f_{X_1}(x_1)\,dx_1=\frac1{2\pi}\int_0^{2\pi}\cos(\theta)\,d\theta=0\\
E(X_2)=0\\
E(X_1X_2)=\int_{-\infty}^\infty \cos(\theta)\sin(\theta)f_{\Theta}(\theta)\,d\theta=\frac1{2\pi}\int_0^{2\pi}\cos(\theta)\sin(\theta)\,d\theta=0\\
E(X_1X_2)=E(X_1)E(X_2)
$$

内积是一个二元运算，$Inner Product: H\times H\longrightarrow \mathbb{R}, <x,y>,x\in H,y\in H$，内积有三个性质：

* 非负性，$\left \langle x,x\right \rangle\geq 0, \left \langle x,x\right \rangle=0\Longrightarrow x=0$；
* 对称性，$\left \langle x,y\right \rangle=\left \langle y,x\right \rangle$
* 双线性性质（Bilinear），$\left \langle \alpha x+\beta y,z\right \rangle=\alpha\left \langle x,z\right \rangle+\beta \left \langle y,z\right \rangle$，$\left \langle x,\alpha y+\beta z\right \rangle=\alpha\left \langle x,y\right \rangle+\beta \left \langle x,z\right \rangle$；

$E(X_1X_2)=E(X_1)E(X_2)$是个内积。$E(X^2)=0\Rightarrow X=0,P(X=0)=1$，此处把概率为1的事件当成确定性事件，尽管不是，则满足性质1，其他性质显然成立。有了内积，可做的事情多了，有了内积就有了角度。线性空间的两个元素的角度——方向余弦，任何线性空间只要在空间中建立了了内积就可以计算角度。两个随机变量之间也会有角度，角度的余弦（即相关系数，Correlated Coefficient）：
$$
\begin{align}
\cos \angle \left \langle x,y\right \rangle&=\frac{\left \langle x,y\right \rangle}{(\left \langle x,x\right \rangle\left \langle y,y\right \rangle)^{\frac12}}\\
&=\frac{E(X_1X_2)}{(EX_1^2EX_2^2)^{\frac12}}
\end{align}
$$
有两个随机变量$X_1,X_2$，掌握的采样数据、研究的位置对象，试图用$X_1$对$X_2$进行表达，用$X_1$的函数逼近$X_2$，$g(X_1)\to X_2$，选择均方距离$\min_g E(g(X_1)-X_2)^2$，在函数空间中搜索，是泛函分析。找一个线性表达$\min_\alpha E(\alpha X_1-X_2)^2$，令$h(\alpha)=E(\alpha X_1-X_2)^2$，只需要对$h(\alpha)$求导：
$$
\nabla _\alpha h(\alpha)=\frac{d}{d\alpha}E(\alpha X_1-X_2)^2=2E(\alpha X_1-X_2)X_1=0\\
\Rightarrow \alpha =\frac{E(X_1X_2)}{E{X_1}^2}
$$
$\alpha =\frac{E(X_1X_2)}{E{X_1}^2}$是线性表达的基本格式，上面是两个随机变量之间角度的距离，下面的是归一化因子。纯集合表示：

![image-20220410135259011](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/332df137035b7417ac8f9b57a5b25561-image-20220410135259011-ca5382.png)

用$X_1$的倍数逼近$X_2$，最优点在投下来的点，$X_2$在$X_1$投影的长度：
$$
\lVert X_2 \rVert \cdot \cos(\theta)=\frac{E(X_1X_2)}{\lVert X_1 \rVert\lVert X_2 \rVert}\cdot\lVert X_2\rVert=\frac{E(X_1X_2)}{\lVert X_1 \rVert}\\
$$
$X_2$在$X_1$投影的长度乘以单位向量的向量：
$$
\frac{E(X_1X_2)}{\left \| X_1 \right \| } \cdot \frac{X_1}{\left \| X_1 \right \| } =\frac{E(X_1X_2)}{\left \| X_1 \right \|^2 }
X_1=\frac{E(X_1X_2)}{EX_1^2}\cdot X_1
$$
上式与解析表达的$\alpha$表达式完全一致。

正交（Orthogonal）：内积$E(X_1X_2)=0\Leftrightarrow \angle\left ( X_1,X_2 \right )=\frac{\pi }{2}$，随机变量也可以正交。

相关系数是方向角的余弦，一定在$(-1, +1)$间。

Cauchy-Schwarz不等式：内积的平方一定小于等于各自的乘积。
$$
\left | \left \langle X,Y \right \rangle  \right |^2 \le \left \langle X,X \right \rangle\cdot \left \langle Y,Y \right \rangle  
$$
变种，是不等式的具体应用，定义好内积即可：
$$
\left ( \sum_{k=1}^{n} x_ky_k \right ) ^2\le \sum_{k=1}^{n}x_k^2\sum_{k=1}^{n}y_k^2  
$$

$$
\int f(x)g(x)dx\le \int f(x)dx\cdot \int g(x)dx
$$

柯西不等式的证明：
$$
\begin{align}
0\le h(\alpha ) & = \left \langle \alpha x+y, \alpha x+y\right \rangle
\\& = \alpha ^2\left \langle x,x \right \rangle+2\alpha \left \langle x,y \right \rangle+\left \langle y,y \right \rangle  
\end{align}
$$

$$
4\left \langle x,y \right \rangle ^2-4\left \langle x,x \right \rangle \left \langle y,y \right \rangle\le 0 
$$

柯西不等式得证。

把相关应用于连续时间随机过程$X(t)$，对随机过程工程实现很重要，时间标定过程特性，每取一个时间对应一个随机过程，有两个不同时刻$t\ge s$，得到两个不同的随机变量$X(t)$、$X(s)$，计算两个随机变量间的相关$E(X(t)X(s))=R_X(t,s)$，这个相关依赖于两个时间，是某个二元函数，称为（自）相关函数（Auto Correlation Function）。

对角线上一定大于零$R_X(t,t)\ge 0$，相关函数是对称的$R_X(t,s)=R_X(s,t)$，有柯西不等式$R^2_X(t,s)\le R_X(t,t)R_X(s,s)$。希望把相关函数简化为一元函数，引入假设。

平稳性（Stationary），是一种不变（Invariance）特性，指随机过程的某一类统计性质随着时间的发展延伸保持不变，平稳与具体哪一类统计性质联系在一起，不同统计性质有这种不变性，有不同的平稳。

希望相关函数满足如下特性：
$$
R_X(t,s)=R_X(t+T,s+T),\forall T\\
R_X(t,s)=R_X(t-s)=R_X(\tau )\\
\tau =t-s
$$
对时间进行平移，时间任意平移对相关函数的取值没影响，意味着相关函数仅仅取决于两个时刻的相对位置（两个时刻间的差值），与绝对位置无关。得到相关函数在平稳假设下的性质：

* 相关函数在零点大于等于0，$R_X(0)\ge 0$；
* 相关函数是偶函数，$R_X(\tau)=R_X(-\tau)$；
* 柯西不等式知相关函数在零点最大，$R_X(0)\ge\mid R_X(\tau)\mid$

这种平稳叫宽平稳（wide-Sense Stationary, w.s.s），严格意义的宽平稳要求均值$m(t)=E(X(t))$，$m(t)\equiv m$均值是常数，平常并不关心，因为达到不难，一个简单的减法$X(t)-m(t)$即可达到，这个条件并不本质。

例子：

幅度相位调制（Amplitude-Phase Modulation），$X(t)=Acos(2\pi f_0t+\theta )$

$A $、$\theta$是独立的$r.v.$，其中$\theta \sim U(0,2\pi )$

计算均值：
$$
\begin{align}
m(t) & = E(X(t))\\ & = E(A)E(cos(2\pi f_0 t+\theta ))\\ 
& =E(A)\frac{1}{2\pi } \int_{0}^{2\pi }  \cos \left ( 2\pi f_0 t+\theta \right ) d\theta \\
&=0
\end{align}
$$
计算相关函数（积化和差），仅仅依赖于两个时刻的差值，是宽平稳：
$$
\begin{align}
R_X(t,s) & = E(X(t)X(s))\\
 & = E(A^2)E( \cos \left ( 2\pi f_0 t+\theta \right ) \cos \left ( 2\pi f_0 s+\theta \right ))\\
&=E(A^2)\frac{1}{2}E(cos(2\pi f_0(t-s))+cos(2\pi f_0(t+s)+2\theta)) \\
&=\frac{1}{2}E(A^2)E(cos(2\pi f_0(t-s))
\end{align}
$$
随机电报信号（Random Telegraph Signal）$Y(t)$，在取值上确定取$1,-1$，跳转是随机的，给定一段时间$[s,t]$，在这段时间内跳转的次数$k$，服从泊松分布，即$P(X_{[s,t]}=k)=\frac{(\lambda (t-s))^k}{k!} exp(-\lambda (t-s))$，泊松分布可看作是二项分布的近似。

相关函数：

同号意味着跳转了偶数次。


$$
\begin{align}
P(Y(t)Y(s) = 1) & = \sum_{k = 0}^{\infty}P(X_{[s,t]} = 2k)\\
 & = \sum_{k = 0}^{\infty } \frac{(\lambda (t-s))^{2k}}{2k!} \cdot exp(-\lambda (t-s))
\end{align}
$$

$$
exp(x) = \sum_{k = 0}^{\infty }\frac{x^k}{k!}\\
\Rightarrow  \sum_{k = 0}^{\infty } \frac{x^{2k}}{(2k)!} = \frac{1}{2}(exp(-x)+exp(x))
$$

$$
\sum_{k = 0}^{\infty } \frac{(\lambda (t-s))^{2k}}{2k!}=\frac{1}{2}(exp(-\lambda (t-s))+exp(\lambda (t-s)))\\
\Rightarrow P(Y(t)Y(s)=1)=\frac{1}{2} (exp(-2\lambda (t-s))+1)\\
P(Y(t)Y(s)=-1)=\frac{1}{2} (-exp(-2\lambda (t-s))+1)\\
$$

$$
\begin{align}
R_Y(t,s) & = E(Y(t)Y(s))\\
& = 1\cdot P(Y(t)Y(s)= 1)+(-1)\cdot P(Y(t)Y(s)= -1)\\
&=exp(-2\lambda (t-s)),(t\ge s)\\
&=exp(-2\lambda|t-s|)
\end{align}
$$

在宽平稳条件下，相关函数是一元函数，只与两个时刻的相对位置有关，与绝对位置无关。

正定性（Positive Definite），函数$f(t)$正定($p.d.$)当且仅当矩阵$R\ge 0$是正定的，任取n个时刻$\forall n,\forall t_1,...,t_n$，构造一个矩阵$R=(f(t_i-t_j))_{ij}$。

正定性是相关函数最本质的性质，包括了前述的相关函数性质。

* $R_X(0)\ge 0$，当$n=1$时，在$t$时刻，$R=R_X(0)\ge 0$；

* 当$n=2$时，在$t_1,t_2$​时刻，
  $$
  R=\begin{pmatrix}
   R_X(0)& R_X(t-s)\\
    R_X(s-t)&R_X(0)
  \end{pmatrix}\ge 0
  $$
  矩阵R正定，所有主子式都是正定的，可得到柯西不等式。

  相关函数为什么是正定的？

  $\forall \alpha=(\alpha_1,...,\alpha_n)^T$，计算二次型$\alpha^TR\alpha$，
  $$
  \begin{align}
  \alpha^TR\alpha & = \sum_{i = 1}^{n} \sum_{j  = 1}^{n} \alpha _i\alpha _jR_X(t_i-t_j) \\
  & = \sum_{i = 1}^{n} \sum_{j  = 1}^{n} \alpha _i\alpha _jE(X(t_i)X(t_j))\\
  &=E(\sum_{i = 1}^{n} \sum_{j  = 1}^{n} \alpha _i\alpha _jX(t_i)X(t_j))\\
  &=E(\sum_{i=1}^{n}\alpha_iX(t_i) )^2\ge 0 
  \end{align}
  $$
  采取一种新的符号体系：

  矢量$X=(X(t_1),...,X(t_n))^T$，矩阵$R=(R_X(t_i-t_j))_{ij}=E(XX^T)$，则$\alpha ^TR\alpha=\alpha ^T E(XX^T)\alpha=E(\alpha ^TXX^T\alpha)=E(\alpha ^TX)^2\ge 0$

  ![image-20220410175040252](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/91f9a55867a3a067020c6176eef4d996-91f9a55867a3a067020c6176eef4d996-image-20220410175040252-9915f4-8083a9.png)

判断矩形窗是不是相关函数，其傅里叶变换是Sa函数。
$$
\lim  _{\tau \to 0}R_X(\tau )=R_X(0)\\
lim_{\tau \to 0}E(X(\tau_0+\tau)-X(\tau_0))^2\\
=lim_{\tau \to 0}E(X^2(\tau_0+\tau))+E(X^2(\tau_0))-2E(X(\tau_0+\tau)X(\tau_0))\\
=2R_X(0)-2R_X(\tau)=0\\
|R_X(\tau_0+\tau)-R_X(\tau_0)|=|E(X(0)X(\tau_0+\tau))-E(X(0)X(\tau_0))|\\
\le E|X(0)||X(\tau_0+\tau)-X(\tau_0)| \le (E|X(0)|^2E|X(\tau_0+\tau)-X(\tau_0)|^2)^{\frac{1}{2}}\\
\Rightarrow\lim  _{\tau \to 0}R_X(\tau _0+\tau )=R_X(\tau_0)
$$

期望的绝对值小于等于绝对值的期望。

一个函数$f(t)$是正定的当且仅当函数的傅里叶变换是正的。频域是正的就是正定的。在数学上和物理上都有意义。（Bochnor）
$$
f(t) \quad is\quad p.d.\Leftrightarrow \int_{-\infty }^{\infty } f(t)exp(-j\omega t)dt\ge 0
$$



## 第三节

回顾：

相关函数$R_X(t,s)=E(X(t),X(s))$刻画的是一个随机过程在两个时刻取值的相关 ，反映的是两个随机变量之间的线性关联。相关函数是一个二元函数，引入宽平稳假设，由二元函数变为一元函数，与两个时刻的绝对位置没有关系，只依赖于二者的差值。平稳性是某类统计性质随着时间的发展延伸而保持不变的特质，平稳性针对某一类统计性质，针对不同的统计性质是不同的平稳类型。

相关函数最核心的性质是正定性（Positive Definite），相关函数一定是正定的。正定函数的定义：
$$
\forall n,\forall t_1,...,t_n,(R_X(t_i-t_j))ij\ge 0
$$
正定性判断的比较简单的性质（Bochner性质）：

一个函数是正定的，其傅里叶变换的函数一定是实的、一定大于等于0，频域上是正的就是正定的。（$f(t)\quad is\quad p.d.\Leftrightarrow \hat{f}(\omega)=\int_{-\infty}^{\infty}f(t)exp(-j\omega t)dt\ge 0$）

这节课主要有两个任务：验证Bochner性质，分析其物理意义。

验证充分性（$\Leftarrow$）：一个函数的傅里叶变换是正的，这个函数一定是正定的。

1. 说明复指数函数是正定的。$exp(j\omega t)\quad is \quad p.d.,\forall \omega \in\mathbb{R}$​
   用定义证明
   $$
   R=(exp(j\omega (t_i-t_j)))_{ij},\forall \alpha\in\mathbb{C}^n,\alpha^HR\alpha\ge0?\\
   \alpha^HR\alpha=\alpha^H(\beta\beta^H)\alpha=\parallel \alpha^HR \parallel ^2\ge0,\beta=(exp(j\omega t_1),...,exp(j\omega t_n))^T
   $$

2. $f(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\hat{f}(\omega)exp(j\omega t)d\omega$  傅里叶反变换，复指数函数是二元函数，如果以$t$为自变量是正定的，相当于若干个正定函数做线性组合，自然是正定的。

验证必要性（$\Rightarrow$）：函数是正定的如何确保其傅里叶变换是正的。

从相关矩阵出发，取一个二次型希望和傅里叶变换去靠近。
$$
f(t)\quad is\quad p.d.\Rightarrow \forall n,\forall t_1,...,t_n,Take\quad \alpha=(exp(-j\omega t_1),...,exp(-j\omega t_n))^T\\
\Rightarrow \sum_{i=1}^{n}\sum_{j=1}^{n}f(t_i-t_j)\alpha_i\overline{\alpha}_j\ge0\Rightarrow \sum_{i=1}^{n}\sum_{j=1}^{n}f(t_i-t_j)exp(-j\omega(t_i-t_j))\ge0\\
$$
此时与傅里叶变换的差别：一个是求和，一个是积分；一个是两重的，一个是一重的。
$$
\Rightarrow \int_{-\frac{T}{2}}^{\frac{T}{2}}\int_{-\frac{T}{2}}^{\frac{T}{2}}f(t-s)exp(-j\omega(t-s))dtds\ge0\\
$$
积分换元三件事：$u=t-s,v=t+s$

* 把所有的旧元换成新元$f(u)exp(-j\omega u)$

* 处理d，差一个雅可比行列式的绝对值  
$$
dtds=\mid det(\frac{\partial (t,s)}{\partial(u,v)})\mid\\
  \frac{\partial (u,v)}{\partial(t,s)}=\begin{pmatrix}
  1&-1 \\
    1&1
  \end{pmatrix} \\
  det(\frac{\partial (u,v)}{\partial(t,s)})=2,
  det(\frac{\partial (t,s)}{\partial(u,v)})=\frac12\\
  \Rightarrow f(u)exp(-j\omega u)\frac12 dudv
$$

* 处理积分限

![image-20220412164024503](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/12/cc8d7b393eae262437853ff14129b22c-cc8d7b393eae262437853ff14129b22c-image-20220412164024503-55c96c-843630.png)

$$
\begin{align}
\Rightarrow \int\int f(u)exp(-j\omega u)\frac12 dudv&=(\int_{-T}^{0} \int_{-u-t}^{u+t}+\int_{0}^{T} \int_{u-t}^{-u+t}) f(u)exp(-j\omega u)\frac12 dudv\ge0 \\
&=\int_{-T}^{T}\int_{\mid u\mid-T}^{-\mid u\mid+T} f(u)exp(-j\omega u)\frac12 dudv\ge0\\
&=\int_{-T}^{T}(T-\mid u\mid)f(u)exp(-j\omega u)du\ge0\\
\end{align}
$$

$$
\Rightarrow \frac 1T \int_{-T}^{T}(T-\mid u\mid)f(u)exp(-j\omega u) du\ge0\quad \forall T\ge0\\
\Rightarrow \int_{-T}^{T}(1-\frac{\mid u\mid}{T})f(u)exp(-j\omega u) du\ge0\\
\Rightarrow When\quad T\rightarrow \infty,\int_{-\infty}^{\infty}f(u)exp(-j\omega u) du\ge0
$$

Bochuner性质的物理意义：随机过程的谱分析（Spectral Analysis of Stochastic Processes）

随机过程的谱分析与确定性信号的谱分析的区别与联系。

确定性信号的谱分析：

* $x(t)$是确定的（deterministic），周期的（Periodic）$x(t)=x(t+T)$
  周期函数一定可以傅里叶展开，写出傅里叶级数。
  $$
  x(t)=\sum_{k=-\infty}^{+\infty}\alpha_kexp(j\frac{2k\pi}{T}t),\alpha_k=\frac1T\int_{-\frac{T}{2}}^{\frac{T}{2}}x(t)exp(-j\frac{2k\pi}{T}t)dt
  $$
  正交基展开，展开系数内积计算,，这个展开要在有限区间内$[-\frac{T}{2},\frac{T}{2}]$展开，时间长度为一个周期长度。
  一个函数不是周期的，也是可以傅里叶展开的，在区间上与展开一致，只能保证区间内与展开一致，区间外是周期延拓。
  
  ![image-20220412182450567](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/12/364203bd5b2df3d8cace81bad2528fc5-image-20220412182450567-e5162b.png)
  
* 非周期的（Non-Periodic），周期可以看成无穷大（$T=\infty$）
  $$
  x(t)=\sum_{k=-\infty}^{+\infty}[\frac1T\int_{-\frac{T}{2}}^{\frac{T}{2}}x(t)exp(-j\frac{2k\pi}{T}t)dt]exp(j\frac{2k\pi}{T}t)\\
  Let\quad \omega_k=\frac{2k\pi}{T}\\
  \Rightarrow x(t)=\frac{1}{2\pi}\sum_{k=-\infty}^{+\infty}[\int_{-\frac{T}{2}}^{\frac{T}{2}}x(t)exp(-j\omega_kt)dt]exp(j\omega_kt)(\omega_k-\omega_{k-1})\\
  Let\quad \Delta\omega_k=\omega_k-\omega_{k-1}\\
  When\quad T\rightarrow\infty,
  \begin{cases}
  x(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}\hat{x}(\omega)exp(j\omega t)d\omega \\
  \hat{x}(\omega)=\int_{-\infty}^{\infty}x(t)exp(-j\omega t)dt
  \end{cases}
  $$
  得到针对非周期信号（更具一般性的信号）的傅里叶变换（Fourior Transform），傅里叶变换是积分形式，不同于傅里叶变换。上面两个式子可以前面都加一个$\frac{1}{\sqrt{2\pi}}$，容易记忆。
  
  如果是随机过程，复指数没有随机性，随机性体现在系数$\alpha_k$上。积分收敛需要绝对可积条件$\int_{-\infty}^{\infty}\mid x(t)\mid dt\le\infty$。
  
  > 所关心的绝大数随机过程不满足绝对可积条件，这些随机过程具有宽平稳的特点，绝对可积意味着随着时间延伸而衰减，衰减意味着有趋势，就不平稳了。平稳一定是在动态不变中，一定是震荡起来的，平稳不意味着平滑，两个点之间的相关仅仅取决于相对位置、差值，不取决于绝对位置。宽平稳不满足绝对可积条件。
  > ![image-20220412202637787](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/12/aead804b8fdf1e7424ced788f4d1519e-image-20220412202637787-a80f02.png)
  
  原本积分想表达点频信息，某一个频点上信号变换的频率信息，积分经常性不收敛意味着这些频点上的频率值为无穷大、发散的$\hat{x}(\omega)=\infty$，对宽平稳信号做正常的傅里叶变换，严格理论意义上在很多频点上频谱不能定义，因为频谱是发散的。准备为随机过程引入谱分析工具，困难在宽平稳过程在很多频点上频谱不能定义，有两条路径。
  

wiener方法：


$X(t)$是随机过程，有三个准备：加窗傅里叶变换，短时傅里叶变换

* 取模求平方，丢失了相位信息，只有幅值信息了；
* 取期望，把握随机过程中的确定性信息
* 用窗长归一化，最后窗不断变大到无穷大。

即$lim_{T\rightarrow \infty}\frac{1}{T}E\mid \int_{-\frac{T}{2}}^{\frac{T}{2}}X(t)exp(-j\omega t)dt \mid^2$
$$
\begin{align}
&\frac{1}{T}E(\int_{-\frac{T}{2}}^{\frac{T}{2}}X(t)exp(-j\omega t)dt)\cdot\overline{(\int_{-\frac{T}{2}}^{\frac{T}{2}}X(s)exp(-j\omega t)ds)}\\
&=\frac{1}{T}\int_{-\frac{T}{2}}^{\frac{T}{2}}\int_{-\frac{T}{2}}^{\frac{T}{2}}E(X(t)X(s))exp(-j\omega (t-s))dtds\\
&=\frac{1}{T}\int_{-\frac{T}{2}}^{\frac{T}{2}}\int_{-\frac{T}{2}}^{\frac{T}{2}}R_X(t-s)exp(-j\omega (t-s))dtds
\end{align}
$$

> 模的平方是自身乘以自身的共轭。

与开始的证明有相似的证明，最后的结果是相关函数的傅里叶变换：
$$
lim_{T\rightarrow \infty}\frac{1}{T}E\mid \int_{-\frac{T}{2}}^{\frac{T}{2}}X(t)exp(-j\omega t)dt \mid^2=\int_{-\infty}^{\infty}R_X(\tau)exp(-j\omega \tau)d\tau
$$
给出了从谱的角度看随机过程，量纲是焦耳，$X(t)$是$I$，$dt$是$t$，量纲是$I^2t$。

定义谱——相关函数的傅里叶变换$S_X(\omega)$。谱：把某种研究对象沿着某个维度进行展开的结果。有二要素：研究对象、维度。例如确定性信号的频谱，研究对象是电流或电压，展开的维度是频率，得到的是某个频率上的电流或者电压值；光谱，研究对象是光的强度，维度是波长，光强在波长维度上进行了分解和展开，看到的是每一个波长上的光强分量；抗菌素的谱，有广谱抗菌素、窄谱抗菌素。研究对象是功率，展开的维度是频率，因此这个新的谱表现出在每一个频点上的功率分量，功率在频率上展开，功率/频率的量纲所以是焦耳。这个新的谱$S_X(\omega)$叫功率谱，准确叫功率谱密度（Power Spectral Density，PSD）。

功率谱的积分不是1积分是常数、和功率联系，功率谱大于等于0。从数学上是正定函数的傅里叶变换；从物理上，![image-20220412212926675](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/12/58b4cc5dc27cb2ac786c4a57ad36fb9e-image-20220412212926675-c86571.png)。这个关系叫Wiener-Khinchin Relation。wiener是控制论之父，著有《Cybernetics》；khinchin是排队论之父。

谱做傅里叶反变换得到相关函数$R_X(\tau)$。
$$
\begin{cases}
 S_X(\omega)=\int_{-\infty}^{\infty}R_X(\tau)exp(-j\omega \tau)d\tau\\
R_X(\tau)=\frac{1}{2\pi}\int_{-\infty}^{\infty}S_X(\omega)exp(j\omega \tau)d\omega
\end{cases}
$$
相关函数在零点的取值$R_X(0)=E\mid X(t) \mid^2$，随机过程其定义为功率（Power）。
$$
Let\quad\tau=0,2\pi R_X(0)=\int_{-\infty}^{\infty}S_X(\omega)d\omega
$$
  功率谱密度是偶函数$S_X(\omega)=S_X(-\omega)$，从物理上也正确，关于频率对称，和负频率相等。从数学上，
$$
\begin{align}
S_X(\omega) & = \int_{-\infty}^{\infty}R_X(\tau)exp(-j\omega \tau)d\tau\\
&=\int_{-\infty}^{\infty}R_X(\tau)cos(\omega\tau)d\tau+j\int_{-\infty}^{\infty}R_X(\tau)sin(\omega\tau)d\tau\\
&=\int_{-\infty}^{\infty}R_X(\tau)cos(\omega\tau)d\tau=S_X(-\omega)
\end{align}
$$

> 相关函数是偶函数$R_X(\tau)=R_X(-\tau)$

信号与系统里，定义好傅里叶变换，就有了频谱，就研究线性时不变系统，关心信号经过线性时不变系统到了频域上的样子，得到结论：时域的卷积对应频域的相乘，即信号的频谱就是系统输入的频谱乘以系统的传递函数（是其冲击响应的傅里叶变换）。在随机信号上延伸：

假定有宽平稳随机过程$X(t)$通过一个线性时不变系统$H$得到一个输出$Y(t)$，$Y(t)=\int_{-\infty}^{\infty}h(t-\tau)X(\tau)d\tau$

![image-20220412215135984](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/12/a7d6ccfaeec455d90f856950cb41efb6-image-20220412215135984-90e79e.png)

$Y$​的相关函数
$$
\begin{align}
R_Y(t,s)&=E(Y(t)\overline{Y(s)})\\
&=E(\int_{-\infty}^{\infty}h(t-\tau)X(\tau)d\tau)\overline{\int_{-\infty}^{\infty}h(s-r)X(r)dr}\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(t-\tau)\overline{h(s-r)}E(X(\tau)\overline{X(r)})d\tau dr\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(t-\tau)\overline{h(s-r)}R_X(\tau-r)d\tau dr
\end{align}
$$

> 小技巧：如何看卷积？卷的两个函数自变量加在一起刚好把积分元消掉；卷积的结果是个函数，并且在加和的地方取值。一维、多维卷积同样如此。

$$
t-\tau+s-r+\tau-r\\
let \quad \tilde{h}(t)=h(-t)\\
=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}h(t-\tau)\overline{\tilde{h}(r-s)}R_X(\tau-r)d\tau dr\quad now\quad t-\tau+r-s+\tau-r=t-s\\
=(h\otimes\overline{\tilde{h}}\otimes R_X)(t-s)
$$

> 尽管你内心很火热，外表也要很光鲜才可以。——真人语录

$Y$的相关函数只与$t-s$​有关，由此得知线性时不变系统，输入是宽平稳，输出也是宽平稳，不改变。
$$
\overline{\tilde{h}(t)}\Rightarrow \int_{-\infty}^{\infty}\overline{\tilde{h}(t)}exp(-j\omega t)dt=\int_{-\infty}^{\infty}\overline{h(-t)}exp(-j\omega t)dt\\
=\int_{\infty}^{\infty}\overline{h(-t)}exp(j\omega t)dt=\overline{\int_{-\infty}^{\infty}\overline{h(t)}exp(-j\omega t)dt}=\overline{H(\omega)}\\
R_Y(\tau)=(h\otimes\overline{\tilde{h}}\otimes R_X)(\tau)\\
\Rightarrow \quad S_Y(\omega)=H(\omega)\overline{H(\omega)}S_X(\omega)=\mid H(\omega) \mid^2S_X(\omega)
$$
线性时不变系统对功率谱密度的改变是系统传递函数模的平方乘以输入信号的功率谱密度，模的平方体现功率的意义。频谱是传递函数乘以输入信号的频谱。

功率谱密度一般没有线性特性。正交时，$S_{X+Y}=S_X(\omega)+S_Y(\omega)$才成立。

随机过程$X(t)$，$Y(t)=\frac1T\int_{t-\frac T2}^{t+\frac T2}X(s)ds$平均器是一个低通滤波，做平均消除高通滤波，是一个线性时不变系统，
$$
\int_{-\infty}^{\infty}h(t-s)X(s)ds\\
h(t-s)=
\begin{cases}
1& \text{ if }t-\frac T2\le s\le t+\frac T2\\
0& \text{others}
\end{cases}\\
\text{矩形窗}\quad
h(t)=
\begin{cases}
1& \text{ if }-\frac T2\le t\le \frac T2\\
0& \text{others}
\end{cases}
$$
传递函数
$$
\begin{align}
H(\omega)&=\int_{-\infty}^{\infty}h(t)exp(-j\omega t)dt\\
&=\frac 1T\int_{-\frac T2}^{\frac T2}exp(j\omega t)dt=\frac{2\sin(\omega\frac T2)}{T\omega}
\end{align}
$$

$$
\mid H(\omega) \mid^2=\frac{4\sin^2(\omega\frac T2)}{T^2\omega^2}\\
S_Y(\omega)=S_X(\omega)\frac{4\sin^2(\omega\frac T2)}{T^2\omega^2}
$$

这是Sa函数的平方，是一个低通滤波，

![image-20220414104819459](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/14/eb6d44efa21fabbef76600c07cb2980b-image-20220414104819459-9b5f40.png)

宽平稳随机过程的相关函数一定满足$R_X(0)-R_X(\tau)\ge \frac 1{4^n}(R_X(0)-R_X(2^n\tau))$，只需证明$R_X(0)-R_X(\tau)\ge \frac 1{4}(R_X(0)-R_X(2\tau))$。
$$
R_X(\tau)=\frac 1{2\pi}\int_{-\infty}^{\infty}S_X(\omega)exp(j\omega\tau)d\omega=\frac 1{2\pi}\int_{-\infty}^{\infty}S_X(\omega)cos(\omega\tau)d\omega\\
3R_X(0)-4R_X(\tau)+R_X(2\tau)\ge0\\
\frac 1{2\pi}\int_{-\infty}^{\infty}S_X(\omega)[3R_X(0)-4R_X(\omega\tau)+R_X(2\omega\tau)]d\omega\\
2(cos(\omega \tau)-1)^2\ge 0\Rightarrow \text{积分大于等于0，结论成立}\\
$$

## 第四节 非平稳现象（Non-Stationary）

Case by Case，注意非在哪

宽平稳$Wide Sense Stationary$，$R_X(t,s)=R_X(t+T,S+T),\forall T$

周期平稳$Cyclostationary\quad X(t)$，$R_X(t,s)=R_X(t+T,S+T),\exist T=R_X(t+kT,S+kT)$

周期平稳介于宽平稳和非平稳之间，与宽平稳差得多远？

$Y(t)=X(t+\theta),\Theta\sim U(0,T),X(t),\Theta,independent$

$R_Y(t,s)=E(Y(t)Y(s))=E(X(t+\theta)X(s+\theta))$，此时相关函数中有两个随机因素$X$和$\theta$,$x()$,随机过程代表样本空间到实数轴的映射，代表随机性体现在样本点，样本点体现在$X$对$\omega$、$\theta$对$\omega$的依赖。引入新工具克服困难——条件期望（Conditional Expectation）。
$$
X,Y,E(Y\mid X)\\
E(Y\mid X)=\int_{-\infty}^{\infty}yf_{Y\mid X}(y\mid x)dy=E(Y\mid X=x)\\
$$
上面的公式有点misleading。

1. 条件期望相比于无条件期望最本质的不同是其是一个随机变量$E(Y\mid X),r.v.$，无条件期望是一个数。$X$的随机性在计算$Y$的期望时暂时消失(temporally disappper)，$Y$的随机性被抹掉，$X$的随机性又回来了，条件期望是一个与$X$有关的随机变量，$Y$的随机性在求期望过程中被消除。
   ![image-20220414124128228](F:/%E5%AD%A6%E4%B9%A0/Learn-notes/image/image-20220414124128228.png)
2. 条件期望最重要的特性，条件期望再取期望就是无条件期望$E_X(E_Y(Y\mid X))=E(Y)$，
证明：
$$
\begin{align}
E_X(E_Y(Y\mid X))&=\int_{-\infty}^{\infty}f_X(x)\int_{-\infty}^{\infty}yf_{Y\mid X}(y\mid x)dydx\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}yf_X(x)f_{Y\mid X}(y\mid x)dxdy\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}yf_{XY}(x,y)dxdy\\
&=\int_{-\infty}^{\infty}yf_Y(y)dy=E(Y)
\end{align}
$$
3. $E(h(X)Y\mid X)=h(X)E(Y\mid X)$，因为$X$的随机性在求期望时暂时消失，所以$h(X)$可以提出来。

例子：
$$
X_1,...,X_n,i.i.d.r.v.,S_n=\sum_{k=1}^nX_k,E(S_n)=\sum_{k=1}^nE(X_k)=nE(X_1)\\
N.r.v.independent,S_N=\sum_{k=1}^NX_k\Rightarrow E(S_N)=NE(X_1)=E(N)E(X_1)?
$$
均值对求和是无条件线性的。项数$N$也是随机变量，是随机个随机变量求和。有很多随机因素，要条件住一部分，各个击破。
$$
E(S_N)=E_N(E_{X_k}(S_N\mid N))=E(E(\sum_{k=1}^NX_k\mid N=n))=E(NE(X_1))=E(X_1)E(N)
$$

$$
\begin{align}
E(X(t+\theta)X(s+\theta))&=E(E(X(t+\theta)X(s+\theta)\mid \theta))\\
&=E_{\theta}(R_X(t+\theta,s+\theta))\\
&=\frac1T\int_{0}^TR_X(t+\theta,s+\theta)d\theta\\
&\overset{\theta'=s+\theta}{=}\frac 1T\int_{s}^{s+T}R_X(t-s+\theta',\theta')d\theta'\\
&=\frac 1T\int_{0}^{T}R_X(t-s+\theta',\theta')d\theta'
\end{align}
$$

结果至于$t-s$有关，变成宽平稳了。周期平稳与宽平稳只差一点，在相位上进行扰动即可，固定的扰动没用，随机的扰动可以，均匀信号就可。

例子：

通信信号（communication signal），有一大类$X(t)=\sum_{k=-\infty}^{+\infty}\alpha_k\Phi(t-kT)$，信息位（Information symbol），符号宽度（symbol width），基带波形（baseland waveform）

在通信系统特别常用BPSK，QPSK，QAM

假设$E(\alpha_k)=0$，宽平稳$E(\alpha_n\alpha_m)=r_{n-m}$，研究功率谱（spectral characteristic）。

相关函数:  波形是确定的，没有随机性。
$$
\begin{align}
R_X(t,s) & = E(X(t),X(s)) \\& = \sum_{k = -\infty }^{+  \infty } \sum_{l = -\infty }^{+  \infty } E(\alpha_k\alpha _l)\Phi(t-kT)\Phi(s-lT)\\
&=\sum_{k = -\infty }^{+  \infty } \sum_{l = -\infty }^{+  \infty } r_{k-l}\Phi(t-kT)\Phi(s-lT)
\end{align}
$$
得出：不宽平稳，但是是周期平稳的随机过程。$R_X(t+T,s+T)=R_X(t,s)$
$$
\begin{align}
\overset{\Theta \sim U(0,T)}{\rightarrow}E(R_X(t+\theta,s+\theta))&=
\frac 1T\int_{0}^T\sum_{k = -\infty }^{+  \infty } \sum_{l = -\infty }^{+  \infty } r_{k-l}\Phi(t-kT+\theta)\Phi(s-lT+\theta)d\theta\\
&\overset{\theta'=s+\theta}{=}\frac 1T\sum_{k = -\infty }^{+  \infty } \sum_{l = -\infty }^{+  \infty }r_{k-l}\int_{s}^{s+T} \Phi(t-s+\theta'-kT)\Phi(\theta'-lT)d\theta'\\
\end{align}
$$
求和换元两件事，不用雅可比，比积分换元简单。

$k'=k-l,l'=l$
$$
\begin{align}
&=\frac 1T\sum_{k = -\infty }^{+  \infty } \sum_{l = -\infty }^{+  \infty }r_{k'}\int_{s}^{s+T} \Phi(t-s+\theta'-(k'+l')T)\Phi(\theta'-l'T)d\theta'\\
&\overset{\theta''=\theta'-l'T}{=}\frac 1T\sum_{k = -\infty }^{+  \infty } \sum_{l = -\infty }^{+  \infty }r_{k'}\int_{s-l'T}^{s-(l'-1)T} \Phi(t-s+\theta''-k'T)\Phi(\theta'')d\theta''\\
&=\frac 1T\sum_{k = -\infty }^{+  \infty } r_{k'}\int_{-\infty}^{+\infty} \Phi(t-s+\theta''-k'T)\Phi(\theta'')d\theta''\\
&=\frac 1T\sum_{k = -\infty }^{+  \infty } r_{k'}R_{\Phi}(t-s-k'T)=\widetilde{R}_X(\tau) 
\end{align}
$$
时间相关函数（time correlation，信号与系统，不同于随机过程）

$R_\Phi(\tau)=\int_{-\infty}^{+\infty}\Phi(\theta''+\tau)\Phi(\theta'')d\theta''$
$$
S_X(\omega)=\int_{-\infty}^{+\infty}\widetilde{R}_X(\tau)exp(-j\omega\tau)d\tau=
\frac 1T\sum_{k = -\infty }^{+  \infty } r_{k'}\int_{-\infty}^{+\infty}R_{\Phi}(\tau-k'T)exp(-j\omega\tau)d\tau\\
\overset{\tau'=\tau-k'T}{=}\frac 1T\sum_{k' = -\infty }^{+  \infty } r_{k'}exp(-j\omega k'T)\cdot\int_{-\infty}^{+\infty}R_{\Phi}(\tau')exp(-j\omega\tau')d\tau'=\frac 1TS_{\alpha}(\omega)\cdot S_{\Phi}(\omega)
$$
前后都是傅里叶变换，离散时间的傅里叶变换，连续时间的傅里叶变换。

$R_\Phi(\tau)=\int_{-\infty}^{+\infty}\Phi(\theta+\tau)\Phi(\theta)d\theta$ 

其傅里叶变换为
$$
\begin{align}
\int_{-\infty}^{+\infty}R_{\Phi}exp(-j\omega \tau)d\tau&=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}\Phi(\theta+\tau)\Phi(\theta)exp(-j\omega \tau)d\tau d\theta\\
&=\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}\Phi(\theta+\tau)exp(-j\omega (\theta+\tau))\Phi(\theta)exp(j\omega \tau)d\tau d\theta\\
&\overset{\tau'=\theta+\tau}{=}\int_{-\infty}^{+\infty}\Phi(\tau')exp(-j\omega\tau')d\tau'\cdot \int_{-\infty}^{+\infty}\Phi(\theta)exp(-j\omega\theta)d\theta\\
&=\mid \Phi(\omega) \mid^2
\end{align}
$$

得到$S_{\alpha}(\omega)\mid \Phi(\omega) \mid^2$，通过线性系统会得到相似的结果，很像，有点卷积的意思，谱特性真的跟卷积很像，这是一个深刻的结果。

> 深刻的结果有三个条件：
>
> * 陈述是简单的；
> * 结果很直观；
> * 论述很困难
>
> ——真人语录

非平稳：

正交增量orthogonal increment，$X(0)=0,\forall t_1<t_2\le t_3<t_4,$相关为0、正交，$X(t_4)-X(t_3)\bot X(t_2)-X(t_1)$，假定$t>s$，计算正交增量过程的相关函数（依赖于小的那个时刻），所以不是宽平稳。
$$
\begin{align}
R_X(t,s)&=E(X(t)X(s))
\\&=E((X(t)-X(s)+X(s))X(s))\\
&=E((X(t)-X(s))X(s))+E(X^2(s))\\
&=E(X^2(s))\\
&=E(X^2(min(s,t)))
\end{align}
$$
（充分必要条件）如果相关函数能写成与两个时刻的最小值有关的函数（具有最小值的形式），一定能推出$X(t)$是正交增量过程。
$$
R_X(t,s)=g(min(t,s))\Rightarrow X(t),orthogonal\quad increasement\\
E((X(t_4)-X(t_3))(X(t_2)-X(t_1)))=R_X(t_4,t_2)+R_X(t_3,t_1)-R_X(t_3,t_2)-R_X(t_4,t_1)\\
=g(t_2)+g(t_1)-g(t_2)-g(t_1)=0
$$
性质：令$t>s，g(\tau)=E(X^2(\tau))$一定是单调上升的函数
$$
\begin{align}
E\mid X(t)-X(s) \mid^2&=g(t)-g(s)\\
&=E(X(t)-X(s))(X(t)-X(s))\\
&=E(X(t)-X(s))X(t)\\
&=E(X^2(t))-E(X(t)X(s))\\
&=EX^2(t)-EX^2(s)\\
&=g(t)-g(s)\ge0
\end{align}
$$
布朗运动（Brown Motion）

* $B(0)=0$；
* 正交增量（Orthogonal Increment）；
* 高斯函数$B(t)-B(s)\sim N(0,\sigma(t-s))$；

正交增量加一个动作变成宽平稳。

假定$X(t)=\frac{\mathrm{d} B(t)}{\mathrm{d} t} $是一个形式化的定义，真正无法求导，布朗运动的每一条轨道处处连续处处不可导。绝大多数函数都是处处连续处处不可导的，取出可导函数的概率为0。阶跃函数可以求导。

> 我们的世界原本就是irregular的，看到的regular都是假象，或者都是幸存者偏差，可以由此指导生活，生活中顺利是偶然的，不顺利才是必然的，Smooth是偶然的，irregular是必然的，生活就是如此。——真人语录

相关函数（形式化的计算，不必纠结细节）：看到了宽平稳，这个结果是白噪声，相关函数是$\delta$，功率谱是常数，每个频率分量都有并且每个频率分量都相等。
$$
\begin{align}
R_X(t,s)&=E(\frac{\mathrm{d} B(t)}{\mathrm{d} t}\frac{\mathrm{d} B(s)}{\mathrm{d} s})\\
 &=\frac{\partial^2}{\partial t\partial s}E(B(t)B(s))\\
 &=\frac{\partial^2}{\partial t\partial s}R_B(t,s)\\
 &=\sigma^2\frac{\partial^2}{\partial t\partial s}min(t,s)\\
 &=\sigma^2\frac{\partial^2}{\partial t\partial s}(\frac 12(t+s)-\mid t-s\mid)\\
 &=-\frac{\sigma^2}{2}\frac{\partial^2}{\partial t\partial s}\mid t-s \mid\\
  &=\sigma^2\delta(t-s)
\end{align}
$$

$$
trick\\\text{最大值是加}
min(t,s)=\frac12 (t+s-\mid t-s \mid)\\
\frac{\partial }{\partial x}\mid x \mid= \begin{cases}
  1& \text{ if } x>0\\
  0& \text{ if } x=0 \\
  -1& \text{ if } x<0
\end{cases}=sgn(x)
$$

> 世界上任何事情上都是有道理的，我们只需知道两件事：1. 有没有必要知道这个道理；2. 有没有能力知道这个道理。——真人语录
>

$$
\frac{\mathrm{d} }{\mathrm{d} x}sgn(x)= \frac{\mathrm{d} }{\mathrm{d} x}(u(x)-u(-x))=2\delta(x)\\
\frac{\mathrm{d} }{\mathrm{d} x}u(x)=\delta(x)
$$

结果推导出了宽平稳。

smooth不同于stationary，越光滑越不平稳。平稳是不同时刻统计性质没有变，趋势和平稳是两回事。前面是不平稳，求导变成了平稳。求导是高通滤波，留下茅草，趋势消除，茅草才是平稳的东西。动态的平衡才是真正的平衡。

## 第五节 多元相关（Multivariate Correlation）

$X,Y,E(XY)$反映的是夹角关系，利用相关比联合分布不像联合分布那样全面，但使用很方便，弥补了联合分布的缺陷。

$X_1,...,X_n$n个随机变量，使用联合分布$f_{X_1,...,X_n}(X_1,...,X_n)$，n元分布很复杂。
$$
E(X_i,X_j),\forall i,j=1,...,n,E(X_i,X_j)=E(X_j,X_i),
\begin{pmatrix}
 n\\
 2
\end{pmatrix}=\frac{n(n-1)}{2}
$$
有很多个，尽管有对称性，但相关数量依然很多，并且看到的是两两相关，依然是一叶障目。

Matrix（对数据的排列方式十分重要）,相关阵（$R_X=(E(X_iX_j))_{ij}$）是对称的，正定的（$R_X=R_X^T,R_X\ge0$）。三个角度阐释相关阵的意义：

* **去相关Decorrelation（白化，whiten）**，相关阵绝大数情况下都不是对角阵，非对角线元不为0，因为不同随机变量有相关，希望成为对角阵，消除不同随机变量之间的相关使其正交。希望找到矩阵$A\in \R^{n\times n},Y=AX\in \R^n,Y=(Y_1,...,Y_n)^T$，$E(Y_iY_j)=0$，A是谁不清楚，但它的作用已知，A作用后随机变量之间的相关性消失，这叫去相关。方程数远远小于未知数个数，解起来麻烦。充分利用相关阵对称正定的特点，$R_Y=E(YY^T)=E(AXX^TA^T)=AE(XX^T)A^T=AR_XA^T$，X、Y的相关阵之间有着密切的关系，并且通过A。目标$R_Y=diag$，合同变换可以做。
  $$
  R_X=U\Lambda U^T=\sum_{k=1}^n\lambda_kU_kU_k^T\Rightarrow U^TR_XU=\Lambda\\
  A=U^T=(U_1,...,U_n)^T
  $$

* **主成分分析（Principal Component Analysis，PCA）**，弄清楚随机矢量在空间中的分布规律，随机点在红线方向（principal direction）拥有最大的散度（largest dispersion）——方差（投影的模的方差，variance of norm of projection），包含多维随机变量最多的信息，加入做某种形式的压缩（compression），压缩到主成分方向，把高维拍成低维，通过某种优化手段找出来。要做三件事：投影，方差，模

![image-20220419163017902](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/19/0541f346ff060e8255713b24bae1fd7c-image-20220419163017902-c1bf87.png)
$$
\alpha\in\R^n,\mid\mid\alpha\mid\mid=1,X\in\R^n\\
Proj_{\alpha}X=\mid\mid X\mid\mid\cdot cos(\theta)\cdot \alpha=\mid\mid X\mid\mid\cdot \frac{<X,\alpha>}{\mid\mid  X\mid\mid\cdot\mid\mid \alpha \mid\mid} \cdot \alpha=<X,\alpha>\cdot \alpha=(\alpha^TX)\cdot\alpha\\
\mid\mid Proj_{\alpha}X\mid\mid=\mid\mid\alpha^TX\mid\mid\cdot\mid\mid\alpha\mid\mid\\
\max_{\alpha}E\mid \alpha^TX \mid,s.t.\mid\mid\alpha\mid\mid=1\Rightarrow \max_{\alpha}E\mid \alpha^TX \mid^2,s.t.\mid\mid\alpha\mid\mid^2=1
$$
投影

![image-20220419164138974](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/19/c7a9812cf30751d849b77a9b1f876d76-image-20220419164138974-22d723.png)
$$
\begin{align}
E\mid\alpha^TX\mid^2&=E(\alpha^TX\cdot X^T\alpha)\\
&=\alpha^TE(XX^T)\alpha=\alpha^TR_X\alpha\\
L(\alpha,\lambda)&=E\mid\alpha^TX\mid^2-\lambda(\mid\mid\alpha\mid\mid^2-1)\\
&=\alpha^TR_X\alpha-\lambda(\alpha^T\alpha-1)\\
\bigtriangledown_\alpha L(\alpha,\lambda) &=2R_X\cdot \alpha-2\lambda\alpha=0\Rightarrow R_X\cdot\alpha=\lambda\alpha\\
\alpha^TR_X\alpha&=\lambda\alpha^T\alpha=\lambda_{max}
\end{align}
$$
第一主成分方向与去相关的，与相关矩阵的特征矢量有关。第二个主成分方向在正交补（orthogonal complement）上找，找到一系列的主成分。这些主成分能大体看待n元分布。

PCA的应用最典型的用在图像压缩上，如果只取目标尺寸的图像，会忽略图像的相关性，要做的是去相关，消除图像的相关性然后再压缩图像。看到的图像一定是高度相关的。返回去的图像会不够锐。

实际做法：把图像切分成若干小块，再做PCA；实际用DCT离散余弦变换，近似于PCA，从理论上可以证明。现在用小波变换DWT。这叫变换编码，下一步是运动预测以及补偿，熵编码。zip是无损压缩。

![image-20220419191902769](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/19/475bb7842477df45013bf70f06a028c9-image-20220419191902769-9a80c7.png)

例子：有随机变量$(X_1,X_2)$，假定标准化过$EX_1=EX_2=0,Var(X_1)=Var(X_2)=1$，相关系数$E(X_1X_2)=\rho$
$$
R_X= \begin{pmatrix}
 1 & \rho\\
 \rho &1
\end{pmatrix}
\\det(R_X-\lambda I)=0\Rightarrow
\left\{\begin{matrix}
\lambda_1=1+\rho\Rightarrow U_1=(1,1)^T\frac{1}{\sqrt{2}} \\
\lambda_2=1-\rho\Rightarrow U_2=(1,-1)^T\frac{1}{\sqrt{2}}
\end{matrix}\right.
$$


> 计算才是四海一家的解决之道

$U_1,U_2$夹角是90度，和$\rho$没有关系。$\rho$和夹角没关系，$\rho$和什么有关系？$\rho$不能决定夹角，什么决定夹角？$\rho=1$，退化成一条线，$\rho=0$，是一个圆，$\rho$决定纺锤的胖瘦，不是夹角关系。方差决定角度。

![image-20220419194107680](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/19/3c05eb875c0434f331e343fa7eeb5832-image-20220419194107680-fad585.png)

* 从展开的角度

$$
Y=AX=U^TX\Rightarrow X=UY=\sum_{k=1}^nU_kY_k
$$

去相关着眼于Y，主成分着眼于X分布的结构，现在也着眼于X的线性表达（linear representation），$U_k$是正交的矢量，是在空间意义下的正交，没有随机性；$Y_k$是标量，也是正交的，是在随机意义下的正交，有随机性。上面的表达式实现了空间、随机的解耦，两者都正交，叫双正交（Bi-Orthogonal），这个展开叫Karhuneun-Loeve Expansion(K-L)。K-L是从相关角度认识随机过程的巅峰，任何随机过程都包含两个部分，一个部分只包含空间或时间信息，另一个只包含随机信息，两者都正交。做以下推广：
$$
X(t)=\sum_{k=-\infty}^{+\infty}\alpha_k\Phi_k(t),\alpha_k,r.v.,E(\alpha_k\alpha_m)=\delta_{km},\int \Phi_k(t)\overline{\Phi_m}dt=\delta_{km}
$$
$\alpha,\Phi$都是正交的
$$
\alpha_k=\int X(t)\overline{\Phi_k(t)}dt\\
R_X(t,s)=E(X(t)X(s))\\
\int R_X(t,s)\Phi_k(s)ds=\lambda_k\Phi_k(t)
$$
实际上类似于求特征值，与$R_X\cdot \Phi=\lambda\Phi$，$\sum_jR_X(i,j)\Phi(j)=\lambda\Phi(i)$一个道理。

上述方程叫Fredholm First Class Integrated Equation。
$$
\int R_X(t,s)\Phi_k(s)ds=\lambda_k\Phi_k(t)
$$
解方程得到特征矢量。假如相关函数满足条件w.s.s$R_X(t,s)=R_X(t-s)$，下式$\int R_X(t-s)\Phi_k(s)ds=\lambda_k\Phi_k(t)$的求解是不是很容易？$\Phi_k=exp(j\omega_kt)$，带入得
$$
\begin{align}
\int_{-\infty}^{+\infty} R_X(t-s)exp(j\omega_kt)ds&\overset{s'=t-s}{=}\int_{-\infty}^{+\infty} R_X(s')exp(j\omega_k(t-s'))ds'\\
&=\int_{-\infty}^{+\infty} R_X(s')exp(j\omega_ks')ds'\cdot exp(j\omega_kt)\\
&=\lambda_k\cdot exp(j\omega_kt)
\end{align}
$$
当宽平稳时，$\Phi_k$就是复三角函数，此时K-L展开与傅里叶展开是一回事。
$$
X(t)=\sum_{k=-\infty}^{+\infty}\lambda_kexp(j\omega_kt)
$$
尝试把上节课走不通的路走通
$$
\begin{align}
X(t)&=\frac{1}{2\pi}\sum_k(\int_{-\frac{T}{2}}^{\frac{T}{2}}X(s)exp(-j\frac{2k\pi}{T}s)ds)\cdot exp(j\frac{2k\pi}{T}t)\cdot\frac{2\pi}{T}\\
&\overset{?}{=}\frac{1}{2\pi}\int_{-\infty}^{+\infty}X(\omega)exp(j\omega t)d\omega\\
\end{align}
\omega_k=\frac{2k\pi}{T},\\
\omega_k-\omega_{k-1}=\frac{2\pi}{T}\\
$$

普通黎曼积分$\int_a^bf(x)dx$，

Stieltjes Integration（积分）$\rightarrow \int_a^bf(x)dg(x)=\sum_kf(X_k)(g(X_k)-g(X_{k-1}))$，$g(x)=x$则回到普通黎曼积分。

只是改变了数学的写法，从物理上没有任何多余的事。

走不通的$X(t)=\int_{-\infty}^{\infty}exp(j\omega t)dF_X(\omega)$可以走通了——宽平稳随机过程的谱表示（Spectual Representation）。如果求导出来，则有间断点，可以将不好的关在笼子里。

> 发扬优点，管理好缺点。18岁之后缺点就很难改变了。不如意者十之八九

随机过程的谱分析合起来：

$dF_X(\omega)$的正交性：

$E(dF(\omega_1)\overline{dF(\omega_2)})=0,(\omega_1\ne \omega_2)$

相当于正交增量过程$E((F_2(\omega_1+\omega_2)-F(\omega_1))\overline{(F_X(\omega_1+\omega_2)-F_1(\omega_2))})=0$。

计算$R_X(t,s)$：
$$
\begin{align}
R_X(t,s)&=E(X(t)\overline{X(s)})\\
&=E(\int_{-\infty}^{+\infty}exp(j\omega t)dF_X(\omega)\int_{-\infty}^{+\infty}exp(j\omega's)dF_X(\omega'))\\
&=E\int_{-\infty}^{+\infty}\int_{-\infty}^{+\infty}exp(j(\omega t-\omega's))E(d(F_X(\omega))\overline{dF_X(\omega ')})\\
&=\int_{-\infty}^{+\infty}exp(j\omega (t-s))E\mid dF_X(\omega) \mid^2\\
&=R_X(t-s)=\frac{1}{2\pi}\int_{-\infty}^{+\infty}exp(j\omega(t-s))S_X(\omega)d\omega
\end{align}
$$
正交的，二维积分退化为一维积分。

得到谱表示和功率谱密度之间的关系。$E\mid dF_X(\omega) \mid^2=\frac{1}{2\pi}S_X(\omega)d\omega$

谱表示通过线性系统后是什么样子？
$$
\begin{align}
Y(t)&=\int_{-\infty}^{+\infty}h(t-\tau)X(\tau)d\tau\\
&=\int_{-\infty}^{+\infty}h(t-\tau)(\int_{-\infty}^{+\infty}exp(j\omega \tau)dF_X(\omega))d\tau\\
&=\int_{-\infty}^{+\infty}exp(j\omega t)(\int_{-\infty}^{+\infty}h(\tau')exp(-j\omega \tau')d\tau')dF_X(\omega)\\
&=\int_{-\infty}^{+\infty}exp(j\omega t)H(\omega)dF_X(\omega)\\
&=\int_{-\infty}^{+\infty}exp(j\omega t)dF_Y(\omega)\\
&\Rightarrow dF_Y(\omega)=H(\omega)dF_X(\omega)
\end{align}
$$
Y的谱过程增量和X的谱过程增量中间就差一个传递函数。就是信号与系统中的频谱关系。$dF_Y(\omega),dF_X(\omega)$是某种东西的频谱。
$$
\begin{align}
\frac{1}{2\pi}S_Y(\omega)d\omega&=E\mid dF_Y(\omega) \mid^2\\
&=E\mid H(\omega)dF_X(\omega)\mid^2\\
&=\mid H(\omega) \mid^2E\mid dF_X(\omega) \mid^2\\
&=\mid H(\omega) \mid^2\frac{1}{2\pi}S_X(\omega)d\omega
\end{align}
$$
得到熟悉的概念。功率谱和谱表示殊途同归。

## 第六节 高斯过程

Gaussian Everywhere，高斯无处不在

Brown motion——爱因斯坦

$f(x,t)$墨水粒子的数量，One-Dimensional Random Motion，x表示空间（spatial），t表示时间（time），$f(x,0)=\delta(x)$。

考虑单个墨水粒子（one particle）,定义一个量（Density，概率密度）$\rho(\tau,y)$，$\int_{-\infty}^{\infty}\rho(\tau,y)dy=1,\rho(\tau,y)\ge0$，期望$\int_{-\infty}^{\infty}y\rho(\tau,y)dy=0$，方差$\int_{-\infty}^{\infty}y^2\rho(\tau,y)dy=D$。

考虑核心方程式
$$
f(x,t+\tau)=\int_{-\infty}^{\infty}f(x-y,t)\rho(\tau,y)dy\\
f(x,t+\tau)=f(x,t)+\frac{\partial f}{\partial t}\cdot \tau\\
f(x-y,t)=f(x,t)-y\cdot\frac{\partial f}{\partial x}+\frac{y^2}{2}\frac{\partial^2 f}{\partial x^2}\\
$$

$$
\begin{align}
f(x,t+\tau)&=f(x,t)+\frac{\partial f}{\partial t}\cdot \tau\\
&=\int_{-\infty}^{\infty}(f(x,t)-y\cdot\frac{\partial f}{\partial x}+\frac{y^2}{2}\frac{\partial^2 f}{\partial x^2})\rho(\tau,y)dy\\
&=f(x,t)+\frac D2\frac{\partial^2 f}{\partial x^2}\\
&\Rightarrow \tau\frac{\partial f}{\partial x}=\frac D2\frac{\partial^2 f}{\partial x^2}\\
&\Rightarrow \frac{\partial f}{\partial x}=\frac {D}{2\tau}\frac{\partial^2 f}{\partial x^2}\\
&\Rightarrow f(x,t)=\frac{\sqrt{\tau}}{\sqrt{2\pi Dt}}\cdot exp(-\frac{\tau x^2}{2Dt})(Gaussian)
\end{align}
$$

泰勒展开只在局部成立，y充分小，大胆假设y足够大也成立，但是吻合实验结果。上述表达式成为扩散方程（Diffusion Equation），表现了粒子的扩散行为。加上边界条件$f(x,0)=\delta(x)$，可以求解此方程式，解刚刚好是高斯分布。

Random Walk随机游动

假定某一个粒子在运动moving particle，规定游动的一维空间，只会走到空间的格点上，定义$P(m,n)$，m是空间spatial，n是时间time。一次只能走一个。
$$
P(m,n)=\frac12(P(m+1,n-1)+P(m-1,n-1))\\
P(m,n+1)-P(m,n)=\frac12(P(m+1,n)+P(m-1,n)-2P(m,n))=\frac12((P(m+1,n)-P(m,n))-(P(m,n)-P(m-1,n)))\\
$$
希望时间上的差分转换成空间上的差分，而且是空间上的二阶差分。
$$
\frac{P(m,n+1)-P(m,n)}{\Delta t}=\frac{D}{2\tau}\frac{P(m+1,n)+P(m-1,n)-2P(m,n)}{(\Delta x)^2}\\
\frac{\Delta t}{(\Delta x)^2}=\frac{\tau}{D}\\
\overset{\Delta t\rightarrow 0,\Delta x\rightarrow 0}{\rightarrow}\frac{\partial P}{\partial t}=\frac{D}{2\tau}\cdot \frac{\partial^2 P}{\partial x^2}\Rightarrow P\sim N(0,\frac{D}{\tau})\\
$$
中心极限定理central limit Theorem

独立同分布i.i.d的一组随机变量$X_1,X_2,...,X_n$，$X_1\sim f_1,X_2\sim f_2,independent,X_1+X_2\sim f_1\otimes f_2$讨论随机变量的和$S_n=X_1+...+X_n$，引入特征函数Characteristic Function。

$X$是随机变量，$f_X(x)$为其分布，$\Phi_X(\omega)=E(exp(j\omega X))=\int_{-\infty}^{\infty}exp(j\omega x)f_X(x)dx$明显是概率密度的傅里叶反变换。
$$
\begin{align}
\Phi_{X_1+X_2}(\omega)&=E(exp(j\omega(x_1+x_2)))\\
&=E(exp(j\omega(x_1))exp(j\omega(x_2)))\\
&=E(exp(j\omega(x_1)))E(exp(j\omega(x_2)))\\
&=\Phi_{X_1}(\omega)\Phi_{X_2}(\omega)
\end{align}
$$
频域相乘，时域一定是卷积的。

结论：

用特征函数证明大数定律
$$
\begin{align}
\Phi_{\frac{X_1+...+X_n}{n}}(\omega)&=E(exp(j\omega \frac{X_1+...+X_n}{n}))\\
&=E(\prod_{k=1}^{n} exp(j \frac{\omega}{n}X_k))\\
&=\prod_{k=1}^{n}E(exp(j \frac{\omega}{n}X_k))(i.i.d)\\
&=(\Phi_{X_1}(\frac{\omega}{n}))^n\\
&=(E(exp(j\frac{\omega}{n}X_1)))^n\\
&=(E(1+j\frac{\omega}{n}X_1+o(\frac 1n)))^n\\
&=(1+j\frac{\omega}{n}E(X_1)+o(\frac{1}{n}))^n\\
&\overset{n\rightarrow \infty}{\rightarrow}exp(j\omega E(X_1))=\Phi_{E(X_1)}(\omega)\\
\end{align}
$$
大数定律（Law of Large Numbers）：给出了统计行为的某种理论基础，上面自由几乎没有
$$
\frac{X_1+...+X_n}{n}\overset{n\rightarrow \infty}{\rightarrow}E(X_1)
$$
中心极限定理，下面给了一定的自由，使其分布规范且唯一。大量的微小的因素叠加在一起所呈现出的整体效应一定是高斯的。
$$
\frac{X_1+...+X_n}{\sqrt{n}}\overset{n\rightarrow \infty}{\rightarrow}N(0,1)
$$

$$
exp(x)=1+x+o(x)\\
(1+\frac an)^n\overset{n\rightarrow \infty}{\rightarrow}exp(a)\\
(1+x)^{\frac1x}\overset{x\rightarrow 0}{\rightarrow}e\\
(1+\frac{a}{n}+o(\frac{1}{n}))^n=(1+\frac1n(a+no(\frac1n)))^n\\
=(1+\frac1n(a+no(\frac1n)))^{\frac{n}{a+no(\frac1n)}}(a+no(\frac1n))\\
no(\frac1n)=\frac{o(\frac1n)}{\frac{1}{n}}\rightarrow0
$$

继续，需要再来一阶展开。
$$
\begin{align}
&=(E(exp(j\frac{\omega}{\sqrt{n}}X)))^n\\
&=(1+j\frac{\omega}{\sqrt{n}}E(X_1)+\frac12 E(j\frac{\omega}{\sqrt{n}}X_1)+o(\frac{1}{n}))^n\\
&=(1-\frac{\omega^2}{2n}E(X_1^2)+o(\frac1n))^n\\
&=(1-\frac{\omega^2}{2n}+o(\frac1n))^n\\
&\overset{n\rightarrow \infty}{\rightarrow}exp(-\frac{\omega^2}{2})\\
&\overset{F}{\rightarrow}\frac{1}{\sqrt{2\pi}}exp(-\frac{x^2}{2})\sim N(0,1)\\
\end{align}
$$

独立的随机变量相加，随机性增加；除以n，随机性减小直至消失；除以$\sqrt{n}$，随机性并没有彻底消失掉，随机的多样性消失，只留下一种——高斯分布。$n\rightarrow\infty$

除以比n小一点点的重对数率$\sqrt{n\ln\ln n}$，这是确定和随机的分界线。

Random walk

每走一格，时间上$\Delta x$，空间上$\Delta t$，每一步是$X_k\sim(1,-1;\frac{1}{2},\frac{1}{2})$，考察$S_n=X_1+...+X_n$，假设$n\Delta t=t$。往右走的步数$B_n$
$$
S_n\Rightarrow B_n\Delta x+(h-B_n)(-\Delta x)=(2B_n-h)\Delta x=2(B_n-\frac n2)\Delta x\\
B_n=Y_1+...+Y_n\\
Y_k\sim (1,0;\frac12,\frac12),E(B_n)=\frac n2\\
E(X)=u,Var(X)=\sigma^2,X=\frac{X-u}{\sigma},E(X)=0,Var(X)=1\\
B_n-\frac n2=\sum_{k=1}^{n}(Y_k-\frac12)\\
$$

$$
\begin{align}
2(B_n-\frac n2)\Delta x&=\frac{B_n-\frac{n}{2}}{\frac{\sqrt{n}}{2}}\sqrt{n}\Delta x\\
&n=\frac{t}{\Delta t}\\
&\overset{n\rightarrow\infty}{\rightarrow}N(0,1)\sqrt{\frac{t}{\Delta t}}\Delta x\\
&=N(0,1)\sqrt{\frac{t(\Delta x)^2}{\Delta t}}\\
&=N(0,\frac{t(\Delta x)^2}{\Delta t})\\
&=N(0,\frac{tD}{2})
\end{align}
$$

Maximum Entropy
$$
-\int_{-\infty}^{+\infty}f(x)\log f(x)dx=H(f),f(x)\ge0,\int_{-\infty}^{+\infty}f(x)dx=1\\
\max_f H(f),s.t.\int_{-\infty}^{+\infty}xf(x)dx=u,\int_{-\infty}^{+\infty}(x-u)^2f(x)dx=\sigma^2
$$
给定均值，方差，最大化熵，考察随机性最强的。这是个泛函。

变分原理（Variational Principle），最速象限（怎么跑时间最短），解决求导问题。

假定$f_0$是最优解（Optional Solution），$H(f)\le H(f_0),\forall f$，构造出与函数相关的正常的函数，正常的函数求导变得毫无困难。
$$
h(t)=H(f_0+tg),h(t)\le h(0)\Rightarrow 0 \quad is \quad optional\quad point\\
\Rightarrow \frac{d}{dt}h(t)\mid _{t=0}=0,h(t)=-\int_{-\infty}^{+\infty}(f_0+tg)\log(f_0+tg)dx\\
L(t,\lambda_0,\lambda_1,\lambda_2)=-\int_{-\infty}^{+\infty}(f_0+tg)\log(f_0+tg)dx+\lambda_0(\int(f_0+tg)dx-1)+\lambda_1(\int_{-\infty}^{+\infty}x(f_0+tg)dx-u)+\lambda_2(\int_{-\infty}^{+\infty}(x-u)^2(f_0+tg)dx-\sigma^2)
$$

$$
0=\frac{d}{dt}L\mid_{t=0}=\int_{-\infty}^{+\infty}(-glog(f_0)-g+\lambda_0g+\lambda_1gx++\lambda_2(x-u)^2g)dx\\
0=\int_{-\infty}^{+\infty}(-log(f_0)-1+\lambda_0+\lambda_1x++\lambda_2(x-u)^2)g(x)dx\\
\Rightarrow -1+\lambda_0+\lambda_1x+\lambda_2(x-u)^2=log(f_0)\\
\Rightarrow f_0(x)=exp(-1+\lambda_0+\lambda_1x+\lambda_2(x-u)^2)
$$

高斯在所有给定均值方差情况下的熵最大，最随机。
