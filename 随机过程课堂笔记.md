---
layout: post
author: Wang Weiying
---

## 第二节

随机变量（Random Variables）是研究不确定性现象的基本工具，是从样本空间映射到实数轴的函数$X:\Omega \rightarrow \mathbb{R}$，样本空间的每一个点都会在实数轴有一个数对应，随机变量的作用是把样本空间给量化，样本空间的点是随机试验的结果，随机变量使得能用数学工具去研究随机试验，随机变量自身没有不确定性，它是确定性的函数。根据样本空间是否可数分成两类：

* Discrete 分布律$P(X=x_k)=P_k$
* Continuous 概率密度$f_X(x)$

随机过程就是一大堆或一组的随机变量。其角标未必表达是时间，只是对若干随机变量的标记。如果表达是时间，随机过程看作是过程，时间意味着在考察某种发展（evolution）随时间变化的规律。其角标还未必是一维的，还有可能是二维的$X_{ij}$，称为随机场（Random Field）。

* $X_1,X_2,...,X_n$，这样标定称为离散指标（Discrete Index）；

* $X(t)$，这样标定称为连续指标（Continuous Index）；一方面是时间的函数，另一方面具有随机性，严格意义上是一个二元函数$X(w,t)$，时间参数$t$提供其“过程”属性，样本空间的样本点（样本参数）$\omega$提供其“随机”属性，谓之“随机过程”。

随机过程关心的是随机过程在不同时刻取值的随机变量之间的相互关联（交互）（Relation（Interaction））。

联合分布(Joint Distribution) $f_{X_1,X_2}(x_1,x_2)$:

* $f_{X_1,X_2}(x_1,x_2)\geq 0$
* $\int_{-\infty}^{\infty} f_{X_1,X_2}(x_1,x_2)\, dx_1dx_2=1$
* Boundary Distribution $f_{X_1}(x_1)=\int_{-\infty}^{\infty}f_{X_1,X_2}(x_1,x_2)\, dx_2$

联合分布是两个随机变量联合起来的分布行为：

$P(x_1 < X_1\leq x_1+\Delta x_1, x_2 < X_2\leq x_2+\Delta x_2)\approx f_{X_1,X_2}(x_1,x_2)\Delta x_1 \Delta x_2$

一个二元函数复杂度很高，研究随机变量之间的关联，联合分布虽然包含的信息很丰富、描述问题很透彻，但是很复杂，希望引入新的工具。

![image-20220410102605112](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/987b8743d4a53682dffc56d07f7f42dd-image-20220410102605112-cf7fff.png)

两者之间不存在关联，$X_2$的分布没有随着$X_1$​的分布发生变化。

独立，两者的联合分布可以写成边缘分布的乘积：

$f_{X_1,X_2}(x_1,x_2)=f_{X_1}(x_1)f_{X_2}(x_2)$

![image-20220410102657030](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/bd2e222a4c0e2c283d6f6c7b7237b1a7-image-20220410102657030-67109c.png)

两者之间存在相互关联（Interaction），$X_2$的分布随着$X_1$的分布发生变化。

![image-20220410102949782](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/c2f58b8450973caa5565b525efbcebf7-image-20220410102949782-5d0884.png)

两者之间存在线性关联（Correlation，linear），即相关性，$X_2$随着$X_1$增大而变大。

n个随机变量的联合分布，用条件手段来简化，控制一部分随机变量的随机性，随机性暂时看作是确定的，研究少量随机变量的随机性，复杂度得到下降。n个随机变量的联合分布分解成n个一元函数的乘积。但是条件是很复杂的，带来了约束（Constraint），把困难从目标转移到约束，并没有解决问题。恒同变换并没有简化问题，化简不等于简化，化简是把问题化为原有形式，简化要引入假设（Assumption），假设并不是退缩。假设的三个特点：

* Simple Description，陈述非常简单；
* Really Effective，确实有效；
* Widely Applicable，假设应用特别广泛，在现实中广泛成立。

> 约束本身是难度的一部分：两点之间直线最短；如果在球面上，北京纽约、北京夏威夷距离差不多，在球面上问题变得复杂；椭球上，用椭圆积分解决问题；任意曲面，怎么走最短，是测地线问题（Geodesic）。

$$
\begin{align}
P(X_1,X_2,...,X_n) & = P(X_n|X_{n-1},...,X_1)P(X_{n-1},...,X_1)\\
 & = P(X_n|X_{n-1},...,X_1)P(X_{n-1}|X_{n-2},...,X_1)...P(X_2|X_1)P(X_1)
\end{align}
$$

条件太复杂使得矛盾转移，并没有解决矛盾，条件住很多时刻，可以只保留离目标时刻的一个最近时刻，称为马尔科夫性。这种假设是马尔可夫假设。

> 不马尔可夫的都是逆天的，马尔可夫的东西才是会存活下来的 。——真人语录

随机过程就学习两种关联：相关性、马尔科夫性。
$$
\begin{align}
P(X_1,X_2,...,X_n) & = P(X_n|X_{n-1},...,X_1)P(X_{n-1},...,X_1)\\
 & = P(X_n|X_{n-1})P(X_{n-1}|X_{n-2})...P(X_2|X_1)P(X_1)
\end{align}
$$
研究$X_1,X_2$的关联，首先需要有一个度量（距离）Metric(Distance) ，均方度量$d(X_1,X_2)=(E|X_1-x_2|^2)^{1/2}$，开方是为了确保是距离，距离要满足三角不等式。距离大关联大，距离小关联小
$$
E|X_1-x_2|^2=E|X_1|^2+E|X_2|^2-2E|X_1X_2|^2
$$
$\Longrightarrow$ 更关心交叉项$E(X_1X_2)$，这个计算叫做相关。两个随机变量相关可以写成下式。
$$
E(X_1X_2)=E(X_1)E(X_2)
$$
满足上式，称为是不相关的（Uncorrelated）。即做中心化$E(X_1-EX_1)(X_2-EX_2)=E(X_1X_2)-E(X_1)E(X_2)$，此时为0。

**独立（Independence）一定不相关，不相关不一定独立。**独立时，联合分布可以写成边缘分布的乘积，推导出相关，见下式：
$$
\begin{align}
E(X_1X_2)&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x_1x_2f_{X_1,X_2}(x_1,x_2)\,dx_1dx_2\\
&=\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}x_1x_2f_{X_1}(x_1)f_{X_2}(x_2)\,dx_1dx_2\\
&=\int_{-\infty}^{\infty}x_1f_{X_1}(x_1)\,dx_1\int_{-\infty}^{\infty}x_2f_{X_2}(x_2)\,dx_2=E(X_1)E(X_2)
\end{align}
$$

不相关、不独立的例子：
$$
\Theta\sim U(0,2\pi)\quad X_1=\cos (\theta),X_2=\sin(\theta),X_1^2+X_2^2=1\\
E(X_1)=\int_{-\infty}^\infty x_1f_{X_1}(x_1)\,dx_1=\frac1{2\pi}\int_0^{2\pi}\cos(\theta)\,d\theta=0\\
E(X_2)=0\\
E(X_1X_2)=\int_{-\infty}^\infty \cos(\theta)\sin(\theta)f_{\Theta}(\theta)\,d\theta=\frac1{2\pi}\int_0^{2\pi}\cos(\theta)\sin(\theta)\,d\theta=0\\
E(X_1X_2)=E(X_1)E(X_2)
$$

内积是一个二元运算，$Inner Product: H\times H\longrightarrow \mathbb{R}, <x,y>,x\in H,y\in H$，内积有三个性质：

* 非负性，$\left \langle x,x\right \rangle\geq 0, \left \langle x,x\right \rangle=0\Longrightarrow x=0$；
* 对称性，$\left \langle x,y\right \rangle=\left \langle y,x\right \rangle$
* 双线性性质（Bilinear），$\left \langle \alpha x+\beta y,z\right \rangle=\alpha\left \langle x,z\right \rangle+\beta \left \langle y,z\right \rangle$，$\left \langle x,\alpha y+\beta z\right \rangle=\alpha\left \langle x,y\right \rangle+\beta \left \langle x,z\right \rangle$；

$E(X_1X_2)=E(X_1)E(X_2)$是个内积。$E(X^2)=0\Rightarrow X=0,P(X=0)=1$，此处把概率为1的事件当成确定性事件，尽管不是，则满足性质1，其他性质显然成立。有了内积，可做的事情多了，有了内积就有了角度。线性空间的两个元素的角度——方向余弦，任何线性空间只要在空间中建立了了内积就可以计算角度。两个随机变量之间也会有角度，角度的余弦（即相关系数，Correlated Coefficient）：
$$
\begin{align}
\cos \angle \left \langle x,y\right \rangle&=\frac{\left \langle x,y\right \rangle}{(\left \langle x,x\right \rangle\left \langle y,y\right \rangle)^{\frac12}}\\
&=\frac{E(X_1X_2)}{(EX_1^2EX_2^2)^{\frac12}}
\end{align}
$$
有两个随机变量$X_1,X_2$，掌握的采样数据、研究的位置对象，试图用$X_1$对$X_2$进行表达，用$X_1$的函数逼近$X_2$，$g(X_1)\to X_2$，选择均方距离$\min_g E(g(X_1)-X_2)^2$，在函数空间中搜索，是泛函分析。找一个线性表达$\min_\alpha E(\alpha X_1-X_2)^2$，令$h(\alpha)=E(\alpha X_1-X_2)^2$，只需要对$h(\alpha)$求导：
$$
\nabla _\alpha h(\alpha)=\frac{d}{d\alpha}E(\alpha X_1-X_2)^2=2E(\alpha X_1-X_2)X_1=0\\
\Rightarrow \alpha =\frac{E(X_1X_2)}{E{X_1}^2}
$$
$\alpha =\frac{E(X_1X_2)}{E{X_1}^2}$是线性表达的基本格式，上面是两个随机变量之间角度的距离，下面的是归一化因子。纯集合表示：

![image-20220410135259011](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/332df137035b7417ac8f9b57a5b25561-image-20220410135259011-ca5382.png)

用$X_1$的倍数逼近$X_2$，最优点在投下来的点，$X_2$在$X_1$投影的长度：
$$
\lVert X_2 \rVert \cdot \cos(\theta)=\frac{E(X_1X_2)}{\lVert X_1 \rVert\lVert X_2 \rVert}\cdot\lVert X_2\rVert=\frac{E(X_1X_2)}{\lVert X_1 \rVert}\\
$$
$X_2$在$X_1$投影的长度乘以单位向量的向量：
$$
\frac{E(X_1X_2)}{\left \| X_1 \right \| } \cdot \frac{X_1}{\left \| X_1 \right \| } =\frac{E(X_1X_2)}{\left \| X_1 \right \|^2 }
X_1=\frac{E(X_1X_2)}{EX_1^2}\cdot X_1
$$
上式与解析表达的$\alpha$表达式完全一致。

正交（Orthogonal）：内积$E(X_1X_2)=0\Leftrightarrow \angle\left ( X_1,X_2 \right )=\frac{\pi }{2}$，随机变量也可以正交。

相关系数是方向角的余弦，一定在$(-1, +1)$间。

Cauchy-Schwarz不等式：内积的平方一定小于等于各自的乘积。
$$
\left | \left \langle X,Y \right \rangle  \right |^2 \le \left \langle X,X \right \rangle\cdot \left \langle Y,Y \right \rangle  
$$
变种，是不等式的具体应用，定义好内积即可：
$$
\left ( \sum_{k=1}^{n} x_ky_k \right ) ^2\le \sum_{k=1}^{n}x_k^2\sum_{k=1}^{n}y_k^2  
$$

$$
\int f(x)g(x)dx\le \int f(x)dx\cdot \int g(x)dx
$$

柯西不等式的证明：
$$
\begin{align}
0\le h(\alpha ) & = \left \langle \alpha x+y, \alpha x+y\right \rangle
\\& = \alpha ^2\left \langle x,x \right \rangle+2\alpha \left \langle x,y \right \rangle+\left \langle y,y \right \rangle  
\end{align}
$$

$$
4\left \langle x,y \right \rangle ^2-4\left \langle x,x \right \rangle \left \langle y,y \right \rangle\le 0 
$$

柯西不等式得证。

把相关应用于连续时间随机过程$X(t)$，对随机过程工程实现很重要，时间标定过程特性，每取一个时间对应一个随机过程，有两个不同时刻$t\ge s$，得到两个不同的随机变量$X(t)$、$X(s)$，计算两个随机变量间的相关$E(X(t)X(s))=R_X(t,s)$，这个相关依赖于两个时间，是某个二元函数，称为（自）相关函数（Auto Correlation Function）。

对角线上一定大于零$R_X(t,t)\ge 0$，相关函数是对称的$R_X(t,s)=R_X(s,t)$，有柯西不等式$R^2_X(t,s)\le R_X(t,t)R_X(s,s)$。希望把相关函数简化为一元函数，引入假设。

平稳性（Stationary），是一种不变（Invariance）特性，指随机过程的某一类统计性质随着时间的发展延伸保持不变，平稳与具体哪一类统计性质联系在一起，不同统计性质有这种不变性，有不同的平稳。

希望相关函数满足如下特性：
$$
R_X(t,s)=R_X(t+T,s+T),\forall T\\R_X(t,s)=R_X(t-s)=R_X(\tau )\\
\tau =t-s
$$
对时间进行平移，时间任意平移对相关函数的取值没影响，意味着相关函数仅仅取决于两个时刻的相对位置（两个时刻间的差值），与绝对位置无关。得到相关函数在平稳假设下的性质：

* 相关函数在零点大于等于0，$R_X(0)\ge 0$；
* 相关函数是偶函数，$R_X(\tau)=R_X(-\tau)$；
* 柯西不等式知相关函数在零点最大，$R_X(0)\ge\mid R_X(\tau)\mid$

这种平稳叫宽平稳（wide-Sense Stationary, w.s.s），严格意义的宽平稳要求均值$m(t)=E(X(t))$，$m(t)\equiv m$均值是常数，平常并不关心，因为达到不难，一个简单的减法$X(t)-m(t)$即可达到，这个条件并不本质。

例子：

幅度相位调制（Amplitude-Phase Modulation），$X(t)=Acos(2\pi f_0t+\theta )$

$A $、$\theta$是独立的$r.v.$，其中$\theta \sim U(0,2\pi )$

计算均值：
$$
\begin{align}
m(t) & = E(X(t))\\ & = E(A)E(cos(2\pi f_0 t+\theta ))\\ 
& =E(A)\frac{1}{2\pi } \int_{0}^{2\pi }  \cos \left ( 2\pi f_0 t+\theta \right ) d\theta \\
&=0
\end{align}
$$
计算相关函数（积化和差），仅仅依赖于两个时刻的差值，是宽平稳：
$$
\begin{align}
R_X(t,s) & = E(X(t)X(s))\\
 & = E(A^2)E( \cos \left ( 2\pi f_0 t+\theta \right ) \cos \left ( 2\pi f_0 s+\theta \right ))\\
&=E(A^2)\frac{1}{2}E(cos(2\pi f_0(t-s))+cos(2\pi f_0(t+s)+2\theta)) \\
&=\frac{1}{2}E(A^2)E(cos(2\pi f_0(t-s))
\end{align}
$$
随机电报信号（Random Telegraph Signal）$Y(t)$，在取值上确定取$1,-1$，跳转是随机的，给定一段时间$[s,t]$，在这段时间内跳转的次数$k$，服从泊松分布，即$P(X_{[s,t]}=k)=\frac{(\lambda (t-s))^k}{k!} exp(-\lambda (t-s))$，泊松分布可看作是二项分布的近似。

相关函数：

同号意味着跳转了偶数次。


$$
\begin{align}
P(Y(t)Y(s) = 1) & = \sum_{k = 0}^{\infty}P(X_{[s,t]} = 2k)\\
 & = \sum_{k = 0}^{\infty } \frac{(\lambda (t-s))^{2k}}{2k!} \cdot exp(-\lambda (t-s))
\end{align}
$$

$$
exp(x) = \sum_{k = 0}^{\infty }\frac{x^k}{k!}\\
\Rightarrow  \sum_{k = 0}^{\infty } \frac{x^{2k}}{(2k)!} = \frac{1}{2}(exp(-x)+exp(x))
$$

$$
\sum_{k = 0}^{\infty } \frac{(\lambda (t-s))^{2k}}{2k!}=\frac{1}{2}(exp(-\lambda (t-s))+exp(\lambda (t-s)))\\
\Rightarrow P(Y(t)Y(s)=1)=\frac{1}{2} (exp(-2\lambda (t-s))+1)\\
P(Y(t)Y(s)=-1)=\frac{1}{2} (-exp(-2\lambda (t-s))+1)\\
$$

$$
\begin{align}
R_Y(t,s) & = E(Y(t)Y(s))\\
& = 1\cdot P(Y(t)Y(s)= 1)+(-1)\cdot P(Y(t)Y(s)= -1)\\
&=exp(-2\lambda (t-s)),(t\ge s)\\
&=exp(-2\lambda|t-s|)
\end{align}
$$

在宽平稳条件下，相关函数是一元函数，只与两个时刻的相对位置有关，与绝对位置无关。

正定性（Positive Definite），函数$f(t)$正定($p.d.$)当且仅当矩阵$R\ge 0$是正定的，任取n个时刻$\forall n,\forall t_1,...,t_n$，构造一个矩阵$R=(f(t_i-t_j))_{ij}$。

正定性是相关函数最本质的性质，包括了前述的相关函数性质。

* $R_X(0)\ge 0$，当$n=1$时，在$t$时刻，$R=R_X(0)\ge 0$；

* 当$n=2$时，在$t_1,t_2$​时刻，
  $$
  R=\begin{pmatrix}
   R_X(0)& R_X(t-s)\\
    R_X(s-t)&R_X(0)
  \end{pmatrix}\ge 0
  $$
  矩阵R正定，所有主子式都是正定的，可得到柯西不等式。

  相关函数为什么是正定的？

  $\forall \alpha=(\alpha_1,...,\alpha_n)^T$，计算二次型$\alpha^TR\alpha$，
  $$
  \begin{align}
  \alpha^TR\alpha & = \sum_{i = 1}^{n} \sum_{j  = 1}^{n} \alpha _i\alpha _jR_X(t_i-t_j) \\
  & = \sum_{i = 1}^{n} \sum_{j  = 1}^{n} \alpha _i\alpha _jE(X(t_i)X(t_j))\\
  &=E(\sum_{i = 1}^{n} \sum_{j  = 1}^{n} \alpha _i\alpha _jX(t_i)X(t_j))\\
  &=E(\sum_{i=1}^{n}\alpha_iX(t_i) )^2\ge 0 
  \end{align}
  $$
  采取一种新的符号体系：

  矢量$X=(X(t_1),...,X(t_n))^T$，矩阵$R=(R_X(t_i-t_j))_{ij}=E(XX^T)$，则$\alpha ^TR\alpha=\alpha ^T E(XX^T)\alpha=E(\alpha ^TXX^T\alpha)=E(\alpha ^TX)^2\ge 0$

  ![image-20220410175040252](https://cdn.jsdelivr.net/gh/WWeiying/Figurebed/blog-images/2022/04/10/91f9a55867a3a067020c6176eef4d996-91f9a55867a3a067020c6176eef4d996-image-20220410175040252-9915f4-8083a9.png)

判断矩形窗是不是相关函数，其傅里叶变换是Sa函数。
$$
\lim  _{\tau \to 0}R_X(\tau )=R_X(0)\\
lim_{\tau \to 0}E(X(\tau_0+\tau)-X(\tau_0))^2\\
=lim_{\tau \to 0}E(X^2(\tau_0+\tau))+E(X^2(\tau_0))-2E(X(\tau_0+\tau)X(\tau_0))\\
=2R_X(0)-2R_X(\tau)=0\\
|R_X(\tau_0+\tau)-R_X(\tau_0)|=|E(X(0)X(\tau_0+\tau))-E(X(0)X(\tau_0))|\\
\le E|X(0)||X(\tau_0+\tau)-X(\tau_0)| \le (E|X(0)|^2E|X(\tau_0+\tau)-X(\tau_0)|^2)^{\frac{1}{2}}\\
\Rightarrow\lim  _{\tau \to 0}R_X(\tau _0+\tau )=R_X(\tau_0)
$$

期望的绝对值小于等于绝对值的期望。

一个函数$f(t)$是正定的当且仅当函数的傅里叶变换是正的。频域是正的就是正定的。在数学上和物理上都有意义。（Bochnor）
$$
f(t) \quad is\quad p.d.\Leftrightarrow \int_{-\infty }^{\infty } f(t)exp(-j\omega t)dt\ge 0
$$















